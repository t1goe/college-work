{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "altered-silly",
   "metadata": {},
   "source": [
    "Thomas Igoe // 17372013\n",
    "\n",
    "HLT Assignement 2 code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-bubble",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "latin-search",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "from nltk.data import find"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-beverage",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "celtic-conjunction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove all emojis from string\n",
    "def remove_emojis(text):\n",
    "    return text.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "def preprocess_text(t):\n",
    "    x = re.sub(r'http\\S+', '', t)\n",
    "    x = re.sub(r'[?!.]+[ ]*', '\\n', x)\n",
    "    x = re.sub(r'[^A-Za-z0-9 \\n]+', '', x)\n",
    "    x = remove_emojis(x) + \"\\n\"\n",
    "    x = x.lower()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "utility-hazard",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Builds a corpus of top level comments for a subreddit\n",
    "# When basic is true only write all.txt\n",
    "def build_subreddit_corpus(subreddit, reddit):\n",
    "    post_limit = 5\n",
    "\n",
    "    overall = open(subreddit + \".txt\", \"w\", encoding='utf8')\n",
    "\n",
    "    # on the following line you can change top to any of the previously mentioned ways of sorting\n",
    "    # and the limit to however many posts you would like to extract (here we extract just 10).\n",
    "\n",
    "    count = 0\n",
    "    httpCount = 0\n",
    "    for post in tqdm(reddit.subreddit(subreddit).top(limit=post_limit)):\n",
    "        count = count + 1\n",
    "#         print(\"Working on post \" + str(count) + \"/\" + str(post_limit) + \" in \" + subreddit)\n",
    "#         print(str(count) + \"/\" + str(post_limit))\n",
    "\n",
    "        # this section collects the comments\n",
    "        for comment in post.comments:\n",
    "\n",
    "            if isinstance(comment, MoreComments):\n",
    "                continue\n",
    "                \n",
    "            if comment.body == \"[removed]\" or comment.body == \"[deleted]\":\n",
    "                continue\n",
    "            \n",
    "#             formatted_comment = re.sub(r'http\\S+', '', comment.body)\n",
    "#             formatted_comment = re.sub(r'[^A-Za-z0-9 ]+', '', formatted_comment)\n",
    "#             formatted_comment = remove_emojis(formatted_comment) + \"\\n\"\n",
    "#             formatted_comment = formatted_comment.lower()\n",
    "            formatted_comment = preprocess_text(comment.body)\n",
    "            try:\n",
    "                overall.write(formatted_comment)\n",
    "            except UnicodeEncodeError:\n",
    "                print(\"String contains character causing errors:\")\n",
    "                print(formatted_comment)\n",
    "\n",
    "    overall.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-career",
   "metadata": {},
   "source": [
    "Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "vocational-cycle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ci = \"f2CDXIEJMw9amg\"  # your client id\n",
    "cs = \"dS2I4meWoXMgQ-AtZObOO8C5WM_smw\"  # your client secret\n",
    "ua = \"HLTUCDScript\"  # your user agent name\n",
    "sub = \"todayilearned\"  # the name of the subreddit (not including the 'r/')\n",
    "\n",
    "# nltk.download('punkt')\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=ci,\n",
    "    client_secret=cs,\n",
    "    user_agent=ua\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "cordless-governor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:19,  3.96s/it]\n"
     ]
    }
   ],
   "source": [
    "build_subreddit_corpus(sub, reddit)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-homeless",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "subject-dynamics",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "illegal\n",
      "('unlawful', 0.684056282043457)\n",
      "('illicit', 0.6780931949615479)\n",
      "('unauthorized', 0.6431363224983215)\n",
      "('illegally', 0.6315262317657471)\n",
      "('prohibited', 0.5762737393379211)\n",
      "('improper', 0.559694766998291)\n",
      "('unlicensed', 0.5309865474700928)\n",
      "('immoral', 0.5182058811187744)\n",
      "('outlawed', 0.5061932802200317)\n",
      "('lawful', 0.5048670172691345)\n",
      "('prohibiting', 0.4972344636917114)\n",
      "('banning', 0.48888346552848816)\n",
      "\n",
      "escape\n",
      "('escaping', 0.7494346499443054)\n",
      "('escaped', 0.6909701228141785)\n",
      "('escapes', 0.6680198907852173)\n",
      "('flee', 0.6065598130226135)\n",
      "('evade', 0.587550699710846)\n",
      "('dodge', 0.5451339483261108)\n",
      "('avoid', 0.5135192275047302)\n",
      "('fleeing', 0.4816117286682129)\n",
      "('survive', 0.47348666191101074)\n",
      "('sneak', 0.46246737241744995)\n",
      "('extricate', 0.44613707065582275)\n",
      "('spared', 0.43854498863220215)\n",
      "\n",
      "smart\n",
      "('intelligent', 0.6495276689529419)\n",
      "('dumb', 0.5792694687843323)\n",
      "('savvy', 0.567413330078125)\n",
      "('clever', 0.5656731724739075)\n",
      "('smarter', 0.5632593631744385)\n",
      "('shrewd', 0.5591171383857727)\n",
      "('canny', 0.4836934804916382)\n",
      "('astute', 0.47846952080726624)\n",
      "('wise', 0.47077280282974243)\n",
      "('thoughtful', 0.4704931974411011)\n",
      "('stupid', 0.47047194838523865)\n",
      "('sensible', 0.46989578008651733)\n",
      "\n",
      "joke\n",
      "('jokes', 0.7732844352722168)\n",
      "('joking', 0.6558836698532104)\n",
      "('funny', 0.6281928420066833)\n",
      "('laugh', 0.622102677822113)\n",
      "('laughing', 0.5821486711502075)\n",
      "('gag', 0.5629411935806274)\n",
      "('skit', 0.5565374493598938)\n",
      "('funnier', 0.5533062815666199)\n",
      "('prank', 0.5512061715126038)\n",
      "('laughs', 0.5449538826942444)\n",
      "('chuckle', 0.5391302108764648)\n",
      "('stupid', 0.53553307056427)\n",
      "\n",
      "marriage\n",
      "('marriages', 0.8137203454971313)\n",
      "('matrimony', 0.691714346408844)\n",
      "('Marriage', 0.6813589930534363)\n",
      "('marry', 0.655377984046936)\n",
      "('marrying', 0.6493963599205017)\n",
      "('divorce', 0.6397972702980042)\n",
      "('married', 0.6383227705955505)\n",
      "('marital', 0.6353872418403625)\n",
      "('wed', 0.6337448358535767)\n",
      "('divorced', 0.6067233681678772)\n",
      "('unmarried', 0.5722571611404419)\n",
      "('remarry', 0.5661296248435974)\n",
      "\n",
      "daughter\n",
      "('mother', 0.8706233501434326)\n",
      "('niece', 0.8637569546699524)\n",
      "('granddaughter', 0.8516314029693604)\n",
      "('son', 0.8468295335769653)\n",
      "('daughters', 0.8136500120162964)\n",
      "('sister', 0.7814772129058838)\n",
      "('wife', 0.766221821308136)\n",
      "('grandmother', 0.7483130097389221)\n",
      "('husband', 0.7383989095687866)\n",
      "('aunt', 0.7379629611968994)\n",
      "('father', 0.7374971508979797)\n",
      "('grandson', 0.7254317402839661)\n",
      "\n",
      "weed\n",
      "('weeds', 0.6674372553825378)\n",
      "('weeded', 0.543906033039093)\n",
      "('pest', 0.4981327950954437)\n",
      "('pests', 0.48367127776145935)\n",
      "('dandelion', 0.4824880361557007)\n",
      "('bud', 0.4719806909561157)\n",
      "('shrub', 0.46653831005096436)\n",
      "('dope', 0.4597589075565338)\n",
      "('grubs', 0.45849865674972534)\n",
      "('grasses', 0.45562225580215454)\n",
      "('clover', 0.45453155040740967)\n",
      "('prune', 0.4491925835609436)\n",
      "\n",
      "hack\n",
      "('hacking', 0.6848268508911133)\n",
      "('hackers', 0.6351537108421326)\n",
      "('hacked', 0.6180554628372192)\n",
      "('snoop', 0.44450026750564575)\n",
      "('worm', 0.42985275387763977)\n",
      "('stab', 0.4274868667125702)\n",
      "('malicious', 0.42154446244239807)\n",
      "('snooping', 0.42062368988990784)\n",
      "('Hack', 0.41556212306022644)\n",
      "('poke', 0.41038066148757935)\n",
      "('steal', 0.40883150696754456)\n",
      "('flaw', 0.40707841515541077)\n",
      "\n",
      "war\n",
      "('wars', 0.7484660744667053)\n",
      "('War', 0.6410670876502991)\n",
      "('invasion', 0.5892110466957092)\n",
      "('Iraq', 0.588599681854248)\n",
      "('occupation', 0.5506216287612915)\n",
      "('conflict', 0.550618588924408)\n",
      "('hostilities', 0.5422784090042114)\n",
      "('warfare', 0.531399667263031)\n",
      "('wartime', 0.5205851793289185)\n",
      "('Wars', 0.5023171901702881)\n",
      "('battlefields', 0.49283021688461304)\n",
      "('battlefield', 0.4810532331466675)\n",
      "\n",
      "black\n",
      "('white', 0.8092215061187744)\n",
      "('blacks', 0.589222252368927)\n",
      "('brown', 0.5766680836677551)\n",
      "('blue', 0.5492398142814636)\n",
      "('whites', 0.547528088092804)\n",
      "('gray', 0.5271324515342712)\n",
      "('colored', 0.5222643613815308)\n",
      "('nonwhite', 0.5023412108421326)\n",
      "('Black', 0.489393949508667)\n",
      "('red', 0.4841255247592926)\n",
      "('African', 0.4755951762199402)\n",
      "('purple', 0.4739382565021515)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)\n",
    "\n",
    "x = ['illegal', 'escape', 'smart', 'joke', 'marriage', 'daughter', 'weed', 'hack', 'war', 'black']\n",
    "\n",
    "# len(model.key_to_index)\n",
    "for y in x:\n",
    "    print(y)\n",
    "    for z in (model.most_similar(y, topn=12)):\n",
    "        print(z)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-pontiac",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "african-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds a corpus of top level comments for a subreddit\n",
    "# When basic is true only write all.txt\n",
    "def build_subreddit_corpus_word(subreddit, reddit):\n",
    "    post_limit = 5\n",
    "    first_letter = 'i'\n",
    "\n",
    "    overall = open(subreddit + \"_words.txt\", \"w\", encoding='utf8')\n",
    "\n",
    "    # on the following line you can change top to any of the previously mentioned ways of sorting\n",
    "    # and the limit to however many posts you would like to extract (here we extract just 10).\n",
    "\n",
    "    count = 0\n",
    "    httpCount = 0\n",
    "    for post in tqdm(reddit.subreddit(subreddit).top(limit=post_limit)):\n",
    "        count = count + 1\n",
    "#         print(\"Working on post \" + str(count) + \"/\" + str(post_limit) + \" in \" + subreddit)\n",
    "#         print(str(count) + \"/\" + str(post_limit))\n",
    "\n",
    "        # this section collects the comments\n",
    "        for comment in post.comments:\n",
    "\n",
    "            if isinstance(comment, MoreComments):\n",
    "                continue\n",
    "                \n",
    "            if comment.body == \"[removed]\" or comment.body == \"[deleted]\":\n",
    "                continue\n",
    "            \n",
    "#             formatted_comment = re.sub(r'http\\S+', '', comment.body)\n",
    "#             formatted_comment = re.sub(r'[^A-Za-z0-9 ]+', '', formatted_comment)\n",
    "#             formatted_comment = remove_emojis(formatted_comment)\n",
    "#             formatted_comment = formatted_comment.lower()\n",
    "            formatted_comment = preprocess_text(comment.body)\n",
    "            for word in formatted_comment.split(' '):\n",
    "                \n",
    "                if word != '' and first_letter != word[0]:\n",
    "                    continue\n",
    "                    \n",
    "                for letter in word:\n",
    "                    try:\n",
    "                        overall.write(letter + ' ')\n",
    "                    except UnicodeEncodeError:\n",
    "                        print(\"letter contains character causing errors:\")\n",
    "                        print(letter)\n",
    "                overall.write(\"\\n\")\n",
    "                \n",
    "\n",
    "    overall.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "sonic-manufacturer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:20,  4.10s/it]\n"
     ]
    }
   ],
   "source": [
    "build_subreddit_corpus_word(sub, reddit) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
